{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa90565-8580-440b-a18b-976c39b5d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.optionmax_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175f973-b286-461c-94f7-f4b35b0052a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_20_21 = pd.read_csv(\"../Clustered_Sessions_FCM.csv\")\n",
    "clustered_sessions_20_21['session_number'] +='-20_21'\n",
    "\n",
    "clustered_sessions_22 = pd.read_csv(\"../Spring_22/Clustered_Sessions_FCM.csv\")\n",
    "clustered_sessions_22['session_number'] +='-22'\n",
    "\n",
    "clustered_sessions_all = pd.concat([clustered_sessions_20_21,clustered_sessions_22])\n",
    "clustered_sessions_all.columns # Use it to get if a session is credit seeking or normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf065e-e6eb-4b8f-9b7b-37e21334af07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To check the percentage of the grades:\n",
    "# 1- Get IDs of students in Fall 20 and those in Spring 21\n",
    "# 2- Make sure no one is in both classes\n",
    "# 3- Create new clustered_sessions_df's and merge with grades (inner), and dicretize\n",
    "# 4- Compare the averages\n",
    "\n",
    "# Probably, I will need to do the Midterm Grades too, based on 10 cutoff, and using a dicretization frequency algorithm\n",
    "\n",
    "grades_20 = pd.read_excel(\"../Grades/Full Grades (Fall'20) - OpenDSA.xlsx\")\n",
    "grades_20_ids = grades_20['OpenDSA ID'].unique()\n",
    "\n",
    "grades_21 = pd.read_excel(\"../Grades/Full Grades (Spring'21) - OpenDSA.xlsx\")\n",
    "grades_21_ids = grades_21['OpenDSA ID'].unique()\n",
    "\n",
    "for idd in grades_20_ids:\n",
    "    if idd in grades_21_ids:\n",
    "        print(idd)\n",
    "for idd in grades_21_ids:\n",
    "    if idd in grades_20_ids:\n",
    "        print(idd)        \n",
    "        \n",
    "# No matching IDs between both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db300152-0d5c-4ec4-a4df-df2c4911ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = pd.concat([grades_20,grades_21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abd518-1550-4e94-95fa-020abb2dccfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_mapping = pd.read_csv('../Grades/User Mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c7a12-52e3-407d-9bc3-4fadc54bf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters = pd.read_excel(\"../Real_Letters.xlsx\")\n",
    "real_letters['last'] = ''\n",
    "real_letters.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e926d16-c819-4e3c-9ad8-e0ebb85db6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee521d-53f7-4332-b337-db3932dbee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in real_letters.iterrows():\n",
    "    if row['Semester']==\"Spring'21\":\n",
    "        real_letters.loc[idx,'last'] = row.Name.split(' ',1)[1]\n",
    "        \n",
    "    elif row['Semester']==\"Fall'20\":\n",
    "        real_letters.loc[idx,'last'] = row.Name.split(',',1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9adb4-d5c5-4163-860b-7cae3f6c331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_letters[['last','first']]= real_letters['Name'].str.split(',', expand=True, n=1)\n",
    "# real_letters[['last','first']]= real_letters['last'].str.split(' ', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8a48e-5e80-4137-9688-5c9b1f26f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.Overall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f95f6-8aef-468d-91f2-6436311aaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.Overall = real_letters.Overall.replace(['A-','B-','B+','C-','C+','D-','D+'],['A','B','B','C','C','D','D'])\n",
    "real_letters = real_letters[~real_letters.Overall.isin(['D','F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc33e3-dbac-4e36-94e0-756171a3dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.Overall.value_counts()#/ len(real_letters.Overall)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3706a12-090d-43ef-8a43-cd080a4fe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.Overall.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e5ec7-dbe6-4ca8-95af-6e9a19fc413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "93+25+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f1619-c351-453f-8324-c1cc7d5fd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789ba32-fde2-45db-9dea-7c6ef44295ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64023986-0662-4587-bceb-1b91a42cc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters = real_letters.merge(user_mapping,how='inner',left_on='last',right_on='last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b64a2f-5622-49c5-b7c5-610ec6d3f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_all = clustered_sessions_20_21[clustered_sessions_20_21.user_id.isin(real_letters['OpenDSA ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6388cc-98f6-4fde-bf87-2f1dbf6fca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_all = clustered_sessions_all[~clustered_sessions_all.user_id.isin([5003,6590, 8670,4837])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b69a4b-ae5d-42bd-8a32-af81f1a8381a",
   "metadata": {},
   "source": [
    "# Predict Final Score as levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885b4d3-3577-4c12-8055-8cdc3a575a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the lowest level ?\n",
    "# What is the chapter names from 1 to 5\n",
    "# Only get those framesets, and train on 20,21, and predict on 22, then try to see what F1 can be improved if not already in shaa allah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e300b5e-2728-4866-871b-28cfb28548e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08561020-6475-4501-baba-f152e5bdd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frameset_Questions_Coarse_Grained = pd.read_csv('../Frameset_Questions_Coarse_Grained.csv')\n",
    "\n",
    "new_df = pd.merge(clustered_sessions_20_21, Frameset_Questions_Coarse_Grained[['frame_name_22','Chapter']],left_on = 'curr_frameset_name', right_on = 'frame_name_22', how='inner')\n",
    "\n",
    "new_df = new_df[new_df.Chapter<=5]\n",
    "\n",
    "\n",
    "new_df = new_df.pivot_table(columns='curr_frameset_name',index=['user_id','cluster'],aggfunc=len,values='u').fillna(0).reset_index()\n",
    "\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff62fd5-2dd2-400c-a7e9-3992b233f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_names = ['Ch1: Introduction', 'Ch2: Mathematical Background', 'Ch3: Finite Acceptors', 'Ch4: Regular Languages', 'Ch5: Identifying Non-regular Languages', 'Ch6: Context-Free Grammars and Languages',\n",
    "'Ch7: Pushdown Automata', 'Ch8: Properties of Context-free Languages', 'Ch9: Turing Machines', 'Ch10: Parsing', 'Ch11: Limits to Computing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa9b1b-ed77-4258-9206-0183476d36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "Y = [2,8,8,22,12,11,10,7,5,0,9]\n",
    "gfg = sns.barplot(y=Y, x=chapter_names, color='purple')#,kind=\"kde\")\n",
    "gfg.set(\n",
    "    # xlabel=\"Module Number\",\n",
    "    # ylabel=\"Number of Framesets\",\n",
    "    # title=\"Frequency of Framesets Attempted Per Sutdent\",\n",
    "    # xticks=(range(0, max(n_frames_per_student) + 3, 2)),\n",
    ")\n",
    "ax.set_xlabel(\"Chapter name\", fontsize = 12,labelpad=20) \n",
    "ax.set_ylabel(\"Number of framesets\",  fontsize = 12) \n",
    "ax.set_xticklabels(chapter_names, rotation = 90)\n",
    "plt.bar_label(gfg.containers[0])\n",
    "plt.show()\n",
    "# The x-axis is # of framesets attempted, The y-axis is the # of students who attempted the same # of framesets\n",
    "fig.savefig(\"Chapters-Division.pdf\", facecolor=\"white\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46c766-ac49-425d-8969-b15ec7d3457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsk_count  = new_df[new_df.cluster=='Credit Seeking'].set_index('user_id').drop('cluster',axis=1)\n",
    "normal_count  = new_df[new_df.cluster=='Normal'].set_index('user_id').drop('cluster',axis=1)\n",
    "\n",
    "\n",
    "agg_count = pd.DataFrame(columns=crsk_count.columns,index=crsk_count.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c6539-e99c-45e4-a91e-e47c23c81c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "for user_id in agg_count.index:\n",
    "    for chapter_number in agg_count.columns:\n",
    "        crsk = crsk_count.loc[user_id, chapter_number] if user_id in crsk_count.index else 0\n",
    "        nrml = normal_count.loc[user_id, chapter_number]  if user_id in normal_count.index else 0\n",
    "        if crsk + nrml ==0:\n",
    "            agg_count.loc[user_id, chapter_number] = 0\n",
    "        else:\n",
    "            agg_count.loc[user_id, chapter_number] = nrml  / (nrml + crsk)\n",
    "# except Exception as E:\n",
    "#     print([user_id, chapter_number] )\n",
    "\n",
    "agg_count = agg_count.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee492c2c-9cd3-40f5-ae53-751bfcd8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of each cell in the spreadsheet represents the proportion of the normal attempts for this frameset.\n",
    "# For example, if a student has attempted the frameset “GrammarIntroFS” 3 times (3 sessions), and he twice did it as credit-seeking, and once as a normal attempt, \n",
    "# then the value of the corresponding cell will be (⅓). \n",
    "\n",
    "# Using this spreadsheet, I was able to reach eventually an accuracy up to 68.75% by using RandomForestClassifier. The F-score for each class is the following: [A, B, C]\n",
    "# I believe that this accuracy is pretty much high given that these framesets were totally optional. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e610a-2711-4323-849c-ab2ea94d964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters[\"Overall\"] .value_counts()#/ len(grades_20_21[\"Letter Grade\"] )*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80a462-c2cd-4281-818e-4418992c5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(real_letters[\"Overall\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfce1eb-c524-4a49-929e-f73e8c48d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = grades_20_21.set_index('OpenDSA ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f531d-cc1f-47b4-90ff-a13f1d940986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Y = \n",
    "X ='Final Score'\n",
    "# res = stats.linregress(sessions_attributes_fine_grained_multi[X], sessions_attributes_fine_grained_multi[Y])\n",
    "# rvalue, pvalue = stats.pearsonr(x=sessions_attributes_fine_grained_multi[X], y=sessions_attributes_fine_grained_multi[Y])\n",
    "# print(f\"R: {res.rvalue}\")\n",
    "# print(\"P-value\", pvalue)\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "gfg = sns.ecdfplot(data=grades_20_21, x=X)\n",
    "\n",
    "axs.set_xlabel( xlabel='Overall score', fontsize = 12 ) \n",
    "axs.set_ylabel( ylabel='Proportion', fontsize = 12) \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "fig.savefig(\"Overall-Score-CDF.pdf\", facecolor=\"white\",dpi=500)\n",
    "\n",
    "# It means whether there are multiple number of choices or not, we may classifiy it as credit seeking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0041a-56ef-4ecc-a8d7-3023c75540f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_letters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba4665-d910-4ec0-9cce-8b6cfd905cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3632aa-4646-4eba-b0cd-70b81f65af99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(real_letters, agg_count, how='inner', left_on= 'OpenDSA ID', right_index=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec0c13-d67a-4f82-a97f-53a99773ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df['Overall'].to_numpy()\n",
    "# all_y_numerical = merged_df[\"Final Score\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,10:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8589b-c47f-4127-afb0-d25977c7dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd39d5-4ac8-4cca-a527-b118cf28c8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "136 - 116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5fbe8-fbaf-41af-a93c-437a89211514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e14c2f-0f55-4c50-8fe9-5958c6f6f847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     all_X, all_y, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "\n",
    "# clf = svm.SVC(max_iter=10000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "# test_score = clf.score(X_test, y_test)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "# # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # The point of this method is that since only 1/10 of your data is in the test set, it is unlikely that all your minority class samples end up in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecc88e-921b-4409-9b66-41ac769fe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model = svm.SVC(max_iter=10000)\n",
    " \n",
    "result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = k)\n",
    "print(np.mean(result))\n",
    "# 0.717983193277311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c21a8-4ae5-4b18-b449-63e608120dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_y = merged_df[\"Overall\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,10:] \n",
    "cv_scores = []\n",
    "sm = RandomOverSampler()#\n",
    "all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro'}\n",
    "\n",
    "clf = svm.SVC(max_iter=10000)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "scores = cross_validate(clf, all_X_normalized, all_y_oversampled, cv=10,scoring=scoring)\n",
    "print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "print()\n",
    "cv_scores.append( np.mean(scores['test_acc']))\n",
    "# Accuracy: 0.89\n",
    "# F1-Score: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fc0eb-b671-4f3e-ba58-8021cf3c505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f2c4d-c982-4927-860f-e838f5c0277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X_normalized,\n",
    "                                                    all_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=all_y,\n",
    "                                                    random_state=11)\n",
    "\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, random_state=None)\n",
    "model = LogisticRegression(solver= 'liblinear').fit(all_X_resambled, all_y_resambled)\n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test,y_test) \n",
    "# result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = kf)\n",
    "# print(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e7d22-52a2-4ef2-84ff-90e9ba16dbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, random_state=None)\n",
    "model = LogisticRegression(solver= 'liblinear')\n",
    " \n",
    "result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = kf)\n",
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53bcfa-2fa9-40d4-ab18-41c2a3d31f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "model = svm.SVC(max_iter=3000)\n",
    " \n",
    "result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = 10)\n",
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9f2b9-f983-429f-9a0e-253e640ff8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "scores = cross_validate(model, all_X_resambled, all_y_resambled, cv=10,scoring=scoring)\n",
    "print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "# Accuracy: 0.9\n",
    "# F1-Score: 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261a2a8-2b15-465b-a537-5e8197647326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84da0a9-9093-43d0-baed-3ffbe37d717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To report: \n",
    "# Using All framesets that were included, we use SVC and we get: cross-val score of 0.727, and a test score of 0.743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b196e-457a-48cf-9af6-303242618e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f92c-e6dc-4384-9d1f-6922c490a1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X_normalized,\n",
    "                                                    all_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=all_y,\n",
    "                                                    random_state=11)\n",
    "\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(sampling_strategy='all', random_state=11)],\n",
    "                                ['classifier', LogisticRegression()]])\n",
    "\n",
    "# stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "#                                        shuffle=True,\n",
    "#                                        random_state=11)\n",
    "    \n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],       'classifier__penalty' : ['l1', 'l2'],      'classifier__C' : np.logspace(-4, 4, 20),    'classifier__solver' : ['liblinear'],\n",
    "       # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', ]\n",
    "    },\n",
    "       { \n",
    "     'classifier' : [ LinearSVC(max_iter=3000)],     \n",
    "       },\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],     'classifier__n_estimators' : list(range(10,101,10)), 'classifier__bootstrap': [True],     'classifier__max_depth': [80, 90, 100, 110], \n",
    "    'classifier__min_samples_leaf': [3, 4, 5], 'classifier__min_samples_split': [8, 10, 12], # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', 'all']\n",
    "   } ,]\n",
    "\n",
    " # 'classifier__max_features': [2, 3],\n",
    "        \n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           # scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    " \n",
    "sm = RandomOverSampler()\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "grid_search.fit(all_X_resambled, all_y_resambled,)\n",
    "cv_score = grid_search.best_score_ # This is already the cv score, and I will include all the data into the cv and nothing for test score\n",
    "print(cv_score)\n",
    "# test_score = grid_search.score(X_test, y_test)\n",
    "# print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf568b-c2ff-45ca-a1ca-5df8c876cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4bdbc-dd7d-44e8-8f63-f27d0c54afce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a feature attribute\n",
    "\n",
    "# new_df_crsk_count = pd.DataFrame( columns= ['UserID']+framset_names) \n",
    "# new_df_crsk_count['UserID'] = userIDs\n",
    "# new_df_crsk_count.set_index( 'UserID', inplace=True) \n",
    "# new_df_crsk_count = new_df_crsk_count.fillna(0)\n",
    "\n",
    "# new_df_normal_count = new_df_crsk_count.copy()\n",
    "\n",
    "# new_df_agg = new_df_crsk_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528db2a-7e7e-496f-b5a5-9c6ef6f4e431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Credit Seeking':\n",
    "#         new_df_crsk_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Normal':\n",
    "#         new_df_normal_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# for row_id in range(len(new_df_normal_count)):\n",
    "#     for col_id in range(len(new_df_normal_count.columns)):\n",
    "#         new_df_agg.iloc[row_id, col_id] = new_df_normal_count.iloc[row_id, col_id] / (new_df_crsk_count.iloc[row_id, col_id]+new_df_normal_count.iloc[row_id, col_id])\n",
    "        \n",
    "# new_df_agg = new_df_agg.fillna(0)\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# new_df_normal_count[\"CrSk Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "# new_df_normal_count[\"Normal Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "\n",
    "# new_df_crsk_count.to_csv(\"new_df_crsk_count.csv\")\n",
    "# new_df_normal_count.to_csv(\"new_df_normal_count.csv\")\n",
    "# new_df_agg.to_csv(\"new_df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce993c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://udc.vt.edu/irdata/data/courses/grades\n",
    "# In Fall 2020, we have 70 enrollments \n",
    "# In Spring 2021, we have 65 enrollments\n",
    "# In Spring 2022, we have 75 enrollments\n",
    "\n",
    "# So having a file \"Coarse-grained_Clustered_Sessions.csv\" means \n",
    "# there's something wrong and we must remove students/accounts to sum up to 70+65 = 135. in Fall'20 and Spring'21. \n",
    "# For example, 1270 is Mostafa Mohammed \n",
    "\n",
    "# Correctly in \"Grades_Users.csv\", we have 133 students, and maybe 2 has dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680348f",
   "metadata": {},
   "source": [
    "# Regressor or Classifier based on \"Count of Normal in each frameset separately\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511f92a-28e7-4210-8c70-31f9288bf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b6b96-c373-407f-840c-677637780969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I report the model I used, write clearly why exactly this model, not any other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad0fdf-78ab-42b9-b748-2244bd957310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df_agg  = pd.read_csv('new_df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddc817-9f72-4523-bacf-17a9b66fbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any student who has been registered in two semesters ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00e041-b4bd-48e4-8841-7f8750d4461a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grades_22 = pd.read_csv(\"../Spring_22/all_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = pd.read_excel(\"../Grades/Book1.xlsx\")\n",
    "grades_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b24941-b226-4b21-9c4c-5c0912240a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6a82-26ac-4e6a-9f62-657df072e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no duplicate users between any of the three semester الحمدلله\n",
    "\n",
    "userIDs_22= grades_22.odsa_ID.unique()\n",
    "userIDs_20_21 = grades_20_21['OpenDSA ID'].unique()\n",
    "\n",
    "for user in userIDs_22:\n",
    "    if user in userIDs_20_21:\n",
    "        print(user)\n",
    "print('-'*100)      \n",
    "for user in userIDs_20_21:\n",
    "    if user in userIDs_22:\n",
    "        print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e748fc9-d1cc-4e5e-9760-ff67018efec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://courses.cs.vt.edu/~cs1604/grading.html\n",
    "\n",
    "letter_grade = []\n",
    "for grade in grades_20_21[\"Final Score\"]:\n",
    "    if grade >= 90:\n",
    "        letter_grade.append(\"A\")\n",
    "    elif grade >= 80:\n",
    "        letter_grade.append(\"B\")\n",
    "    elif grade >= 70:\n",
    "        letter_grade.append(\"C\")\n",
    "    elif grade >= 60:\n",
    "        letter_grade.append(\"D\")\n",
    "    else:\n",
    "        letter_grade.append(\"F\")\n",
    "\n",
    "grades_20_21[\"Letter Grade\"] = letter_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20541564-cfbb-4ade-a425-ad8e24f581ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[\"Letter Grade\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93633e89-5648-41b0-a1cc-34f68bcde69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebb6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(grades_20_21[['OpenDSA ID',\"Letter Grade\"]], new_df_agg, how='inner', left_on='OpenDSA ID', right_on='UserID')\n",
    "merged_df.set_index( 'UserID', inplace=True) \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'D'] # Because unbalanced with D and F. So, I am dropping them. \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'F'] # Because unbalanced with D and F. So, I am dropping them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df[\"Letter Grade\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,2:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36b3ae-eff5-4a7d-833f-4658f093b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8e79-584c-44e0-af87-3dc7ced6cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df[\"Letter Grade\"].value_counts())\n",
    "merged_df[\"Letter Grade\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1972b8-074f-4a3b-a02d-f6defdaa8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "58+41+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "all_X_normalized = scaler_X.fit_transform(all_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    all_X, all_y, test_size=0.3, shuffle=True)  # , random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99333-a134-4c7e-8437-7579d8cbc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "sm = RandomOverSampler()#\n",
    "all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    " \n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro'}\n",
    "\n",
    "clf = svm.SVC(max_iter=10000)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "scores = cross_validate(clf, all_X_normalized, all_y_oversampled, cv=10,scoring=scoring)\n",
    "print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "print()\n",
    "cv_scores.append( np.mean(scores['test_acc']))\n",
    "#     Accuracy: 0.71\n",
    "# F1-Score: 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9b37-f04a-476e-a0a8-9c6abf795520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "sm = RandomOverSampler()#\n",
    "all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    " \n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro'}\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "scores = cross_validate(clf, all_X_normalized, all_y_oversampled, cv=10,scoring=scoring)\n",
    "print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "print()\n",
    "cv_scores.append( np.mean(scores['test_acc']))\n",
    "#     Accuracy: 0.71\n",
    "# F1-Score: 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cdf9f-7932-48e7-abbb-28a442830b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a98e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "print(\"CV Score\", clf.best_score_)\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))\n",
    "\n",
    "# 0.6875 --> The best I got earlier 3 months ago\n",
    "# ['A' 'A' 'B' 'A' 'C' 'C' 'B' 'B' 'C' 'B' 'B' 'C' 'A' 'C' 'C' 'A' 'B' 'B'\n",
    "#  'C' 'C' 'B' 'C' 'A' 'B' 'A' 'C' 'B' 'B' 'C' 'A' 'A' 'C']\n",
    "# [0.47058824 0.60869565 0.91666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d1acd-c7e6-486e-a810-2c4dc73f93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56555315-b347-45aa-97df-ee8237324d24",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print(\"Predicted:\", y_pred[i], \" -- Reality\",y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + GridSearchCV: we got accuracy of 66.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression + SMOTE: we got accuracy of 58.3% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression: we got accuracy of 41.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + DL (111,50,25,3): we got accuracy of 41.6% \n",
    "\n",
    "# Using \n",
    "# I have tried reducing the dimensions using PCA, and it turns out we can reduce to 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335320cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=111, n_hidden=45, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.ReLU(),\n",
    "             nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X_normalized, all_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "\n",
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeafcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af175f86-22bb-42d4-be8b-9da547eb0ccd",
   "metadata": {},
   "source": [
    "# Regressor or Classifier based on \"Student % of CrSk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14a8a0-7663-4411-913e-0324e7f6241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as FM\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "# pl.utilities.seed.seed_everything(seed=2) # sets seed for pseudo-random number generators in: pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9c32a-454b-4311-ad2a-63d74f6c8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustered_Users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03eac2-be08-4dba-8017-1cfca84f705c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_X =  Clustered_Users[['# CrSk Attempts','# Nrml Attempts','% of CrSk',\n",
    "#                     'Is CrSk','CrSk Time','Nrml Time','# CrSk Framesets','# Nrml Framesets']].to_numpy()\n",
    "\n",
    "all_X = Clustered_Users[\n",
    "    [\n",
    "        \"# CrSk Attempts\",\n",
    "        \"% of CrSk\",\n",
    "        \"Is CrSk\",\n",
    "        \"CrSk Time\",\n",
    "        \"# CrSk Framesets\",\n",
    "    ]\n",
    "].to_numpy()\n",
    "all_y = Clustered_Users[\"Letter Grade\"].to_numpy()\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "all_X = scaler_X.fit_transform(all_X)\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "# scaler_y = StandardScaler()\n",
    "# all_y = scaler_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33542ff-e5a0-4e54-a146-309404cd9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876a42b-cbd0-44b5-ba94-0fa917851620",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bc48c-dcdf-48f1-b39e-4e4757d1d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b58d8-ca59-447b-a73c-aa210a943054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fada2b-aeba-4e83-80d6-d4cd733138f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# 1- Normalized Version of Credit Seeking\n",
    "# 2- Normalized Version of Normal\n",
    "# 3- Normalized Version of # of framesets in Credit Seeking\n",
    "# 4- Normalized Version of # of framesets in Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00aa373-92c3-4e91-b2b3-0931290a7997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModelRegressor(pl.LightningModule):\n",
    "    def __init__(self, n_features=2, n_hidden=128, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b242fa4-16a2-4464-b00e-df29f741cab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=5, n_hidden=50, n_output=5):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbfa08-7803-4a94-9901-e34330be6789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c48364-6e33-4ba1-8a5d-9fb60715fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Feature: % of Cr Seeking (Standridzed) with many hyperparameters, and the best MSE is 1.1431, Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized),                 and the best MSE is 1.220 , Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized), and the best MSE is 1.00264 , Y = (Midterm 1, Midterm 2, Final Exam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
