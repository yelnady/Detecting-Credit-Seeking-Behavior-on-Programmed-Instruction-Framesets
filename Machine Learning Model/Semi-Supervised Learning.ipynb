{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa90565-8580-440b-a18b-976c39b5d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.optionmax_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91335f63-6224-4aaf-b310-ac649c4c60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import sklearn.svm\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728d88d-bcd3-4bff-969c-9c25864c6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier, LabelPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175f973-b286-461c-94f7-f4b35b0052a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_20_21 = pd.read_csv(\"../Clustered_Sessions_FCM.csv\")\n",
    "clustered_sessions_20_21['session_number'] +='-20_21'\n",
    "\n",
    "clustered_sessions_22 = pd.read_csv(\"../Spring_22/Clustered_Sessions_FCM.csv\")\n",
    "clustered_sessions_22['session_number'] +='-22'\n",
    "\n",
    "clustered_sessions_all = pd.concat([clustered_sessions_20_21,clustered_sessions_22])\n",
    "clustered_sessions_all.columns # Use it to get if a session is credit seeking or normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20be6f1-18f9-4053-be9c-a0c8b4d338b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustered_sessions_all = clustered_sessions_all.fillna(0)\n",
    "clustered_sessions_all # We don't care here about whether 2 interactions or not, bcz the model deosn't cluster unless it's 3 or more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24ed2b-38c5-4769-954d-1b5f2f1cbe0b",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c9e38-3280-48dd-b3c2-17c466683343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What confidence level do we achieve\n",
    "# How much is the accuracy on the proportions that we kept unlabeled\n",
    "# Which model we used\n",
    "# How long it took us to itereate\n",
    "# The attributes we are training on\n",
    "# What is the benefit of adding that to the model\n",
    "\n",
    "# Do we need the PCA steps again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cea08-fa4a-44f0-ac2b-5924a075f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clustered_sessions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c551b0-53b0-42e8-a2d9-b3558f170339",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clustered_sessions_all.iloc[:,5:-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8dba2-62f7-4b9d-8d5c-67844ca6ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_original = clustered_sessions_all['cluster'].to_numpy().copy()\n",
    "\n",
    "\n",
    "target_modified = clustered_sessions_all['cluster'].to_numpy().copy()\n",
    "rng = np.random.RandomState(2)\n",
    "unl_idxs = rng.rand(len(target_modified)) < 0.95 # It means you will create random numbers, we don't know the values, but they are 12645 values, and all range from 0 to 1 (decimals)\n",
    "target_modified[unl_idxs] = -1 # Anything that should be unlabled, according to the model will have to be -1, We used 'unl_idxs' as a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b4ddd-f4d3-4004-8c42-e7a1d9875b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labeled = len(target_modified) - len(target_modified[unl_idxs])\n",
    "n_unlabeled =  len(target_modified[unl_idxs])\n",
    "print(\"Labeled:\", n_labeled, \"Unlabeled:\", n_unlabeled, \" -- % of Labeled\", n_labeled/ len(target_modified),  \"-- % of Unlabeled\", n_unlabeled/ len(target_modified), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84370499-9430-4bfc-94ae-444309aa3c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "lbl = SelfTrainingClassifier(clf,max_iter=20)\n",
    "lbl.fit(data, target_modified)\n",
    "# print (\"Semi_supervised labels:\\n\", y_ pred)\n",
    "y_pred = lbl.predict(data[unl_idxs]) \n",
    "print(classification_report(target_original[unl_idxs], y_pred))  \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9eefa4-cdaa-4c98-93d7-a95cc9bb3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(target_original[unl_idxs], y_pred, average='micro', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c27a2-b1ba-40f9-bd6b-7ae0e5db8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a259d5f-89a5-4d19-824d-3496b2d9f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86b5a2-5fe0-4287-96e2-7ffac5adef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[unl_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802df7d-2c05-48ba-ba6b-8052bcd47d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_original[unl_idxs][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535921ae-44ee-4378-942e-d0deb9f914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[unl_idxs][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c365799-b828-4343-8945-932b5cf9209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d8554c-026a-47b6-8b88-998ac5da940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac3fa6-07a6-4b96-889e-443f31e1110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prop_model = LabelPropagation()\n",
    "lbl.fit(data, target_modified)\n",
    "# print (\"Semi_supervised labels:\\n\", y_ pred)\n",
    "y_pred = lbl.predict(data) \n",
    "print(classification_report(target_original[unl_idxs], y_pred[unl_idxs]))  \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885b4d3-3577-4c12-8055-8cdc3a575a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the lowest level ?\n",
    "# What is the chapter names from 1 to 5\n",
    "# Only get those framesets, and train on 20,21, and predict on 22, then try to see what F1 can be improved if not already in shaa allah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08561020-6475-4501-baba-f152e5bdd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frameset_Questions_Coarse_Grained = pd.read_csv('../Frameset_Questions_Coarse_Grained.csv')\n",
    "\n",
    "new_df = pd.merge(clustered_sessions_20_21, Frameset_Questions_Coarse_Grained[['frame_name_22','Chapter']],left_on = 'curr_frameset_name', right_on = 'frame_name_22', how='inner')\n",
    "\n",
    "# new_df = new_df[new_df.Chapter<=5]\n",
    "\n",
    "\n",
    "new_df = new_df.pivot_table(columns='curr_frameset_name',index=['user_id','cluster'],aggfunc=len,values='u').fillna(0).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f53f7-e21d-4983-834c-cced582d128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frameset_Questions_Coarse_Grained.columns, len(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59c73d-61ea-499c-865a-6a798df6c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Frameset_Questions_Coarse_Grained['frame_name_22'].drop_duplicates().unique())\n",
    "# Frameset_Questions_Coarse_Grained = Frameset_Questions_Coarse_Grained.drop_duplicates(subset=['frame_name_22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff62fd5-2dd2-400c-a7e9-3992b233f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_names = ['Ch1: Introduction', 'Ch2: Mathematical Background', 'Ch3: Finite Acceptors', 'Ch4: Regular Languages', 'Ch5: Identifying Non-regular Languages', 'Ch6: Context-Free Grammars and Languages',\n",
    "'Ch7: Pushdown Automata', 'Ch8: Properties of Context-free Languages', 'Ch9: Turing Machines', 'Ch10: Parsing', 'Ch11: Limits to Computing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa9b1b-ed77-4258-9206-0183476d36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "Y = [2,8,8,22,12,11,10,7,5,0,9]\n",
    "gfg = sns.barplot(y=Y, x=chapter_names, color='purple')#,kind=\"kde\")\n",
    "gfg.set(\n",
    "    # xlabel=\"Module Number\",\n",
    "    # ylabel=\"Number of Framesets\",\n",
    "    # title=\"Frequency of Framesets Attempted Per Sutdent\",\n",
    "    # xticks=(range(0, max(n_frames_per_student) + 3, 2)),\n",
    ")\n",
    "ax.set_xlabel(\"Chapter name\", fontsize = 12,labelpad=20) \n",
    "ax.set_ylabel(\"Number of framesets\",  fontsize = 12) \n",
    "ax.set_xticklabels(chapter_names, rotation = 90)\n",
    "plt.bar_label(gfg.containers[0])\n",
    "plt.show()\n",
    "# The x-axis is # of framesets attempted, The y-axis is the # of students who attempted the same # of framesets\n",
    "fig.savefig(\"Chapters-Division.pdf\", facecolor=\"white\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46c766-ac49-425d-8969-b15ec7d3457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsk_count  = new_df[new_df.cluster=='Credit Seeking'].set_index('user_id').drop('cluster',axis=1)\n",
    "normal_count  = new_df[new_df.cluster=='Normal'].set_index('user_id').drop('cluster',axis=1)\n",
    "\n",
    "\n",
    "agg_count = pd.DataFrame(columns=crsk_count.columns,index=crsk_count.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b22dec-f3a3-4178-b56e-14ba09ffd80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate by Chapter Maybe??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c6539-e99c-45e4-a91e-e47c23c81c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for user_id in agg_count.index:\n",
    "        for chapter_number in agg_count.columns:\n",
    "            crsk = crsk_count.loc[user_id, chapter_number] if user_id in crsk_count.index else 0\n",
    "            nrml = normal_count.loc[user_id, chapter_number]  if user_id in normal_count.index else 0\n",
    "            if crsk + nrml ==0:\n",
    "                agg_count.loc[user_id, chapter_number] = 0\n",
    "            else:\n",
    "                agg_count.loc[user_id, chapter_number] = nrml  / (nrml + crsk)\n",
    "except Exception as E:\n",
    "    print([user_id, chapter_number] )\n",
    "\n",
    "agg_count = agg_count.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee492c2c-9cd3-40f5-ae53-751bfcd8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of each cell in the spreadsheet represents the proportion of the normal attempts for this frameset.\n",
    "# For example, if a student has attempted the frameset “GrammarIntroFS” 3 times (3 sessions), and he twice did it as credit-seeking, and once as a normal attempt, \n",
    "# then the value of the corresponding cell will be (⅓). \n",
    "\n",
    "# Using this spreadsheet, I was able to reach eventually an accuracy up to 68.75% by using RandomForestClassifier. The F-score for each class is the following: [A, B, C]\n",
    "# I believe that this accuracy is pretty much high given that these framesets were totally optional. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054ee4b-ed24-4668-8430-0ba509a27eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grades_22 = pd.read_csv(\"../Spring_22/all_scores.csv\")[['odsa_ID','Final Score']]\n",
    "grades_20_21 = pd.read_excel(\"../Grades/Book1.xlsx\")[['odsa_ID','Final Score']]\n",
    "grades_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368756d-3c3e-4695-aac5-673bff7ef754",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[grades_20_21.odsa_ID==6728]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df70273-0c0f-4d0b-a900-09b375f579c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://courses.cs.vt.edu/~cs1604/grading.html\n",
    "\n",
    "letter_grade = []\n",
    "for grade in grades_20_21[\"Final Score\"]:\n",
    "    if grade >= 90:\n",
    "        letter_grade.append(\"A\")\n",
    "    elif grade >= 80:\n",
    "        letter_grade.append(\"B\")\n",
    "    elif grade >= 70:\n",
    "        letter_grade.append(\"C\")\n",
    "    elif grade >= 63.6:\n",
    "        letter_grade.append(\"D\")\n",
    "    else:\n",
    "        letter_grade.append(\"F\")\n",
    "\n",
    "grades_20_21[\"Letter Grade\"] = letter_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4960b4-1e15-4e8d-a8f2-689fd5048c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[\"Letter Grade\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfce1eb-c524-4a49-929e-f73e8c48d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[\"Final Score\"].plot(kind='box'),grades_20_21[\"Final Score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f531d-cc1f-47b4-90ff-a13f1d940986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = \n",
    "X ='Final Score'\n",
    "# res = stats.linregress(sessions_attributes_fine_grained_multi[X], sessions_attributes_fine_grained_multi[Y])\n",
    "# rvalue, pvalue = stats.pearsonr(x=sessions_attributes_fine_grained_multi[X], y=sessions_attributes_fine_grained_multi[Y])\n",
    "# print(f\"R: {res.rvalue}\")\n",
    "# print(\"P-value\", pvalue)\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "gfg = sns.ecdfplot(data=grades_20_21, x=X)\n",
    "\n",
    "axs.set_xlabel( xlabel='Overall score', fontsize = 12 ) \n",
    "axs.set_ylabel( ylabel='Proportion', fontsize = 12) \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "fig.savefig(\"Overall-Score-CDF.pdf\", facecolor=\"white\",dpi=500)\n",
    "\n",
    "# It means whether there are multiple number of choices or not, we may classifiy it as credit seeking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0041a-56ef-4ecc-a8d7-3023c75540f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba4665-d910-4ec0-9cce-8b6cfd905cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "79.992500-1.5*(90.945-79.99250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3632aa-4646-4eba-b0cd-70b81f65af99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(grades_20_21, agg_count, how='inner', left_on='odsa_ID', right_index=True)\n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'D'] # Because unbalanced with D and F. So, I am dropping them. \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec0c13-d67a-4f82-a97f-53a99773ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df[\"Letter Grade\"].to_numpy()\n",
    "all_y_numerical = merged_df[\"Final Score\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,3:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd39d5-4ac8-4cca-a527-b118cf28c8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df[\"Letter Grade\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5fbe8-fbaf-41af-a93c-437a89211514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e14c2f-0f55-4c50-8fe9-5958c6f6f847",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     all_X, all_y, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "\n",
    "# clf = svm.SVC(max_iter=10000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "# test_score = clf.score(X_test, y_test)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "# # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # The point of this method is that since only 1/10 of your data is in the test set, it is unlikely that all your minority class samples end up in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecc88e-921b-4409-9b66-41ac769fe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model = svm.SVC(max_iter=10000)\n",
    " \n",
    "result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = k)\n",
    "print(np.mean(result))\n",
    "# 0.717983193277311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c21a8-4ae5-4b18-b449-63e608120dac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# # pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# # all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# # print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     all_X_normalized, all_y, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "\n",
    "# sm = SMOTE('all')#\n",
    "# X_train, y_train, = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# clf = LogisticRegression(max_iter=10000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "# test_score = clf.score(X_test, y_test)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e7d22-52a2-4ef2-84ff-90e9ba16dbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "sm = RandomOverSampler()#\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, random_state=None)\n",
    "model = LogisticRegression(solver= 'liblinear')\n",
    " \n",
    "result = cross_val_score(model , all_X_resambled, all_y_resambled, cv = kf)\n",
    "print(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261a2a8-2b15-465b-a537-5e8197647326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cd815-fc76-49cf-a333-c89503929303",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84da0a9-9093-43d0-baed-3ffbe37d717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To report: \n",
    "# Using All framesets that were included, we use SVC and we get: cross-val score of 0.727, and a test score of 0.743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b196e-457a-48cf-9af6-303242618e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f92c-e6dc-4384-9d1f-6922c490a1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X_normalized,\n",
    "                                                    all_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=all_y,\n",
    "                                                    random_state=11)\n",
    "\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(sampling_strategy='all', random_state=11)],\n",
    "                                ['classifier', LogisticRegression()]])\n",
    "\n",
    "# stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "#                                        shuffle=True,\n",
    "#                                        random_state=11)\n",
    "    \n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],       'classifier__penalty' : ['l1', 'l2'],      'classifier__C' : np.logspace(-4, 4, 20),    'classifier__solver' : ['liblinear'],\n",
    "       # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', ]\n",
    "    },\n",
    "       { \n",
    "     'classifier' : [ LinearSVC(max_iter=3000)],     \n",
    "       },\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],     'classifier__n_estimators' : list(range(10,101,10)), 'classifier__bootstrap': [True],     'classifier__max_depth': [80, 90, 100, 110], \n",
    "    'classifier__min_samples_leaf': [3, 4, 5], 'classifier__min_samples_split': [8, 10, 12], # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', 'all']\n",
    "   } ,]\n",
    "\n",
    " # 'classifier__max_features': [2, 3],\n",
    "        \n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           # scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    " \n",
    "sm = RandomOverSampler()\n",
    "all_X_resambled, all_y_resambled, = sm.fit_resample(all_X_normalized, all_y)\n",
    "\n",
    "grid_search.fit(all_X_resambled, all_y_resambled,)\n",
    "cv_score = grid_search.best_score_ # This is already the cv score, and I will include all the data into the cv and nothing for test score\n",
    "print(cv_score)\n",
    "# test_score = grid_search.score(X_test, y_test)\n",
    "# print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf568b-c2ff-45ca-a1ca-5df8c876cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778020e3-a3a0-4aec-8a9f-c46aaf4ccdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import svm\n",
    "all_X_normalized =  MinMaxScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "all_Y_normalized =  MinMaxScaler().fit_transform(all_y_numerical.reshape(-1, 1)) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y_numerical, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "# sm = RandomOverSampler()#\n",
    "# X_train  = sm.fit_resample(X_train )\n",
    "\n",
    "\n",
    "krr = svm.SVR() \n",
    "krr.fit(X_train, y_train.ravel())\n",
    "print(krr.score(X_test, y_test.ravel()))\n",
    "y_pred = krr.predict(X_test)\n",
    "\n",
    "# A constant model that always predicts the expected value of y, disregarding the input features, would get a  score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a8e30-0c48-4a91-a1f0-6fc37c0c2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce626-df24-4777-8f58-a62ff8be9d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4bdbc-dd7d-44e8-8f63-f27d0c54afce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a feature attribute\n",
    "\n",
    "# new_df_crsk_count = pd.DataFrame( columns= ['UserID']+framset_names) \n",
    "# new_df_crsk_count['UserID'] = userIDs\n",
    "# new_df_crsk_count.set_index( 'UserID', inplace=True) \n",
    "# new_df_crsk_count = new_df_crsk_count.fillna(0)\n",
    "\n",
    "# new_df_normal_count = new_df_crsk_count.copy()\n",
    "\n",
    "# new_df_agg = new_df_crsk_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528db2a-7e7e-496f-b5a5-9c6ef6f4e431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Credit Seeking':\n",
    "#         new_df_crsk_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Normal':\n",
    "#         new_df_normal_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# for row_id in range(len(new_df_normal_count)):\n",
    "#     for col_id in range(len(new_df_normal_count.columns)):\n",
    "#         new_df_agg.iloc[row_id, col_id] = new_df_normal_count.iloc[row_id, col_id] / (new_df_crsk_count.iloc[row_id, col_id]+new_df_normal_count.iloc[row_id, col_id])\n",
    "        \n",
    "# new_df_agg = new_df_agg.fillna(0)\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# new_df_normal_count[\"CrSk Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "# new_df_normal_count[\"Normal Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "\n",
    "# new_df_crsk_count.to_csv(\"new_df_crsk_count.csv\")\n",
    "# new_df_normal_count.to_csv(\"new_df_normal_count.csv\")\n",
    "# new_df_agg.to_csv(\"new_df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce993c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://udc.vt.edu/irdata/data/courses/grades\n",
    "# In Fall 2020, we have 70 enrollments \n",
    "# In Spring 2021, we have 65 enrollments\n",
    "# In Spring 2022, we have 75 enrollments\n",
    "\n",
    "# So having a file \"Coarse-grained_Clustered_Sessions.csv\" means \n",
    "# there's something wrong and we must remove students/accounts to sum up to 70+65 = 135. in Fall'20 and Spring'21. \n",
    "# For example, 1270 is Mostafa Mohammed \n",
    "\n",
    "# Correctly in \"Grades_Users.csv\", we have 133 students, and maybe 2 has dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511f92a-28e7-4210-8c70-31f9288bf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b6b96-c373-407f-840c-677637780969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I report the model I used, write clearly why exactly this model, not any other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad0fdf-78ab-42b9-b748-2244bd957310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df_agg  = pd.read_csv('new_df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddc817-9f72-4523-bacf-17a9b66fbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any student who has been registered in two semesters ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00e041-b4bd-48e4-8841-7f8750d4461a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grades_22 = pd.read_csv(\"../Spring_22/all_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = pd.read_excel(\"../Grades/Book1.xlsx\")\n",
    "grades_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b24941-b226-4b21-9c4c-5c0912240a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6a82-26ac-4e6a-9f62-657df072e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no duplicate users between any of the three semester الحمدلله\n",
    "\n",
    "userIDs_22= grades_22.odsa_ID.unique()\n",
    "userIDs_20_21 = grades_20_21['OpenDSA ID'].unique()\n",
    "\n",
    "for user in userIDs_22:\n",
    "    if user in userIDs_20_21:\n",
    "        print(user)\n",
    "print('-'*100)      \n",
    "for user in userIDs_20_21:\n",
    "    if user in userIDs_22:\n",
    "        print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e748fc9-d1cc-4e5e-9760-ff67018efec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://courses.cs.vt.edu/~cs1604/grading.html\n",
    "\n",
    "letter_grade = []\n",
    "for grade in grades_20_21[\"Final Score\"]:\n",
    "    if grade >= 90:\n",
    "        letter_grade.append(\"A\")\n",
    "    elif grade >= 80:\n",
    "        letter_grade.append(\"B\")\n",
    "    elif grade >= 70:\n",
    "        letter_grade.append(\"C\")\n",
    "    elif grade >= 60:\n",
    "        letter_grade.append(\"D\")\n",
    "    else:\n",
    "        letter_grade.append(\"F\")\n",
    "\n",
    "grades_20_21[\"Letter Grade\"] = letter_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20541564-cfbb-4ade-a425-ad8e24f581ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[\"Letter Grade\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93633e89-5648-41b0-a1cc-34f68bcde69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebb6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(grades_20_21[['OpenDSA ID',\"Letter Grade\"]], new_df_agg, how='inner', left_on='OpenDSA ID', right_on='UserID')\n",
    "merged_df.set_index( 'UserID', inplace=True) \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'D'] # Because unbalanced with D and F. So, I am dropping them. \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'F'] # Because unbalanced with D and F. So, I am dropping them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df[\"Letter Grade\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,2:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36b3ae-eff5-4a7d-833f-4658f093b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8e79-584c-44e0-af87-3dc7ced6cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df[\"Letter Grade\"].value_counts())\n",
    "merged_df[\"Letter Grade\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1972b8-074f-4a3b-a02d-f6defdaa8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "58+41+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "all_X_normalized = scaler_X.fit_transform(all_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    all_X, all_y, test_size=0.3, shuffle=True)  # , random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99333-a134-4c7e-8437-7579d8cbc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverSampling\n",
    "\n",
    "sm = RandomOverSampler(sampling_strategy='minority')\n",
    "X_oversampled, y_oversampled = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversampled, y_oversampled, test_size=0.3, shuffle=True)  # \n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9b37-f04a-476e-a0a8-9c6abf795520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OverSampling\n",
    "\n",
    "sm = RandomOverSampler(sampling_strategy='minority')\n",
    "X_oversampled, y_oversampled = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversampled, y_oversampled, test_size=0.3, shuffle=True)  # \n",
    "\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cdf9f-7932-48e7-abbb-28a442830b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a98e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "print(\"CV Score\", clf.best_score_)\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))\n",
    "\n",
    "# 0.6875 --> The best I got earlier 3 months ago\n",
    "# ['A' 'A' 'B' 'A' 'C' 'C' 'B' 'B' 'C' 'B' 'B' 'C' 'A' 'C' 'C' 'A' 'B' 'B'\n",
    "#  'C' 'C' 'B' 'C' 'A' 'B' 'A' 'C' 'B' 'B' 'C' 'A' 'A' 'C']\n",
    "# [0.47058824 0.60869565 0.91666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d1acd-c7e6-486e-a810-2c4dc73f93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56555315-b347-45aa-97df-ee8237324d24",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print(\"Predicted:\", y_pred[i], \" -- Reality\",y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + GridSearchCV: we got accuracy of 66.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression + SMOTE: we got accuracy of 58.3% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression: we got accuracy of 41.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + DL (111,50,25,3): we got accuracy of 41.6% \n",
    "\n",
    "# Using \n",
    "# I have tried reducing the dimensions using PCA, and it turns out we can reduce to 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335320cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=111, n_hidden=45, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.ReLU(),\n",
    "             nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X_normalized, all_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "\n",
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeafcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14a8a0-7663-4411-913e-0324e7f6241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as FM\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "# pl.utilities.seed.seed_everything(seed=2) # sets seed for pseudo-random number generators in: pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9c32a-454b-4311-ad2a-63d74f6c8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustered_Users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03eac2-be08-4dba-8017-1cfca84f705c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_X =  Clustered_Users[['# CrSk Attempts','# Nrml Attempts','% of CrSk',\n",
    "#                     'Is CrSk','CrSk Time','Nrml Time','# CrSk Framesets','# Nrml Framesets']].to_numpy()\n",
    "\n",
    "all_X = Clustered_Users[\n",
    "    [\n",
    "        \"# CrSk Attempts\",\n",
    "        \"% of CrSk\",\n",
    "        \"Is CrSk\",\n",
    "        \"CrSk Time\",\n",
    "        \"# CrSk Framesets\",\n",
    "    ]\n",
    "].to_numpy()\n",
    "all_y = Clustered_Users[\"Letter Grade\"].to_numpy()\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "all_X = scaler_X.fit_transform(all_X)\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "# scaler_y = StandardScaler()\n",
    "# all_y = scaler_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33542ff-e5a0-4e54-a146-309404cd9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876a42b-cbd0-44b5-ba94-0fa917851620",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bc48c-dcdf-48f1-b39e-4e4757d1d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b58d8-ca59-447b-a73c-aa210a943054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fada2b-aeba-4e83-80d6-d4cd733138f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# 1- Normalized Version of Credit Seeking\n",
    "# 2- Normalized Version of Normal\n",
    "# 3- Normalized Version of # of framesets in Credit Seeking\n",
    "# 4- Normalized Version of # of framesets in Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00aa373-92c3-4e91-b2b3-0931290a7997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModelRegressor(pl.LightningModule):\n",
    "    def __init__(self, n_features=2, n_hidden=128, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b242fa4-16a2-4464-b00e-df29f741cab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=5, n_hidden=50, n_output=5):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbfa08-7803-4a94-9901-e34330be6789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c48364-6e33-4ba1-8a5d-9fb60715fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Feature: % of Cr Seeking (Standridzed) with many hyperparameters, and the best MSE is 1.1431, Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized),                 and the best MSE is 1.220 , Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized), and the best MSE is 1.00264 , Y = (Midterm 1, Midterm 2, Final Exam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
