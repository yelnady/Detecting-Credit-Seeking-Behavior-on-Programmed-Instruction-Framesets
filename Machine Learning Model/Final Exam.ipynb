{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7447e65-4246-45c4-9e97-04be26b1e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe current idea: \n",
    "# to classify into grade letters based on the each chapter as a feature, and the value will be based on normal behavior (Earlier Chapters will have more frequencey together so good)\n",
    "# I need to create from the file \"Coarse-grained_Clustered_Sessions.csv\" a new file \"Users_Chapters_CrSK_Count.csv\"\n",
    "# More, if I want to remove specific chapters from being as a feature, I need to rewrite the chapter numbers from OpenDSA to get their order. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097aedb5-00f4-4714-a69b-b414cb2a6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To DO:\n",
    "# 1- Should we chose first 5 weeks, or the first 6 chapters , Using the first 6 chapters all we can predict up to 70% the grade of the student.\n",
    "# 2- Should the features be framesets or chapter numbers\n",
    "# 3- How to predict the Midterm 2 for 20 and 21\n",
    "# 4- Predict Final Grade Letter for 20 and 21\n",
    "\n",
    "# 5- Different SMOTE was the key to success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa90565-8580-440b-a18b-976c39b5d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.optionmax_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175f973-b286-461c-94f7-f4b35b0052a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sessions_20_21 = pd.read_csv(\"../Clustered_Sessions_FCM.csv\")\n",
    "clustered_sessions_20_21['session_number'] +='-20_21'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b69a4b-ae5d-42bd-8a32-af81f1a8381a",
   "metadata": {},
   "source": [
    "# Predict Midterm Score as levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885b4d3-3577-4c12-8055-8cdc3a575a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the lowest level ?\n",
    "# What is the chapter names from 1 to 5\n",
    "# Only get those framesets, and train on 20,21, and predict on 22, then try to see what F1 can be improved if not already in shaa allah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08561020-6475-4501-baba-f152e5bdd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frameset_Questions_Coarse_Grained = pd.read_csv('../Frameset_Questions_Coarse_Grained.csv')\n",
    "\n",
    "new_df = pd.merge(clustered_sessions_20_21, Frameset_Questions_Coarse_Grained[['frame_name_22','Chapter']],left_on = 'curr_frameset_name', right_on = 'frame_name_22', how='inner')\n",
    "\n",
    "new_df = new_df[new_df.Chapter<=5]\n",
    "new_df['Chapter'] = new_df['Chapter'].astype(str)\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79dbcb6-7cc2-4d74-a149-0c1093ae16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_mid = new_df.pivot_table(columns='curr_frameset_name',index=['user_id','cluster'],aggfunc=len,values='u').fillna(0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46c766-ac49-425d-8969-b15ec7d3457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsk_count_mid = new_df_mid[new_df_mid.cluster=='Credit Seeking'].set_index('user_id').drop('cluster',axis=1)\n",
    "normal_count_mid = new_df_mid[new_df_mid.cluster=='Normal'].set_index('user_id').drop('cluster',axis=1)\n",
    "\n",
    "\n",
    "agg_count_mid = pd.DataFrame(columns=crsk_count_mid.columns, index=normal_count_mid.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b22dec-f3a3-4178-b56e-14ba09ffd80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate by Chapter Maybe??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c6539-e99c-45e4-a91e-e47c23c81c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for user_id in agg_count_mid.index:\n",
    "        for chapter_number in agg_count_mid.columns:\n",
    "            crsk = crsk_count_mid.loc[user_id, chapter_number] if user_id in crsk_count_mid.index else 0\n",
    "            nrml = normal_count_mid.loc[user_id, chapter_number]  if user_id in normal_count_mid.index else 0\n",
    "            if crsk + nrml ==0:\n",
    "                agg_count_mid.loc[user_id, chapter_number] = 0\n",
    "            else:\n",
    "                agg_count_mid.loc[user_id, chapter_number] = nrml  / (nrml + crsk)\n",
    "except Exception as E:\n",
    "    print([user_id, chapter_number] )\n",
    "\n",
    "agg_count_mid = agg_count_mid.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffb614-249a-4844-8b99-cd364da5ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# الحمدلله الذي علمني استخدام الـ Pivot Tables صدفة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee492c2c-9cd3-40f5-ae53-751bfcd8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of each cell in the spreadsheet represents the proportion of the normal attempts for this frameset.\n",
    "# For example, if a student has attempted the frameset “GrammarIntroFS” 3 times (3 sessions), and he twice did it as credit-seeking, and once as a normal attempt, \n",
    "# then the value of the corresponding cell will be (⅓). \n",
    "\n",
    "# Using this spreadsheet, I was able to reach eventually an accuracy up to 68.75% by using RandomForestClassifier. The F-score for each class is the following: [A, B, C]\n",
    "# I believe that this accuracy is pretty much high given that these framesets were totally optional. \n",
    "pd.read_excel(\"../Grades/Book1.xlsx\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054ee4b-ed24-4668-8430-0ba509a27eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = pd.read_excel(\"../Grades/Book1.xlsx\")[['odsa_ID', 'Total Homeworks']].fillna(0)\n",
    "grades_20_21.columns\n",
    "grades_20_21 = grades_20_21.set_index('odsa_ID')\n",
    "grades_20_21 = grades_20_21[grades_20_21[ 'Total Homeworks']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e921a05-9a95-4fb2-8298-fd5e80eccbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grades_20_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6272769-b1e2-46fb-a0a8-9d3edea6b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# grades_20_21 = grades_20_21[~grades_20_21['Final Exam'].isin([64,72])]\n",
    "grades_20_21 = grades_20_21[~grades_20_21['Total Homeworks'].isin([155.5, 197.6, 197.6])]\n",
    "temp = np.array(grades_20_21[ 'Total Homeworks']).reshape(-1, 1)\n",
    "grades_20_21['result'] = KBinsDiscretizer(strategy='kmeans', encode='ordinal', n_bins=4).fit_transform(temp)\n",
    "grades_20_21['result'].value_counts() / len(grades_20_21['result'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402ef9a-374a-4ad9-91ac-6ab14cea81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grades_20_21['result'] = grades_20_21['result'].replace(0, 1) # merging the smallest group with the group above it\n",
    "grades_20_21['result'] = grades_20_21['result'].astype(str)\n",
    "grades_20_21['result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb20bc4-adda-4813-9bfe-5b64edb4b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What values the discretizer choose to split at?\n",
    "for i in range(0,8):\n",
    "    print(i, grades_20_21[grades_20_21['result']==str(i)+\".0\"][ 'Total Homeworks'].min()  , grades_20_21[grades_20_21['result']==str(i)+\".0\"][ 'Total Homeworks'].max() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e89771-9e2a-4fd5-85b8-3be8eb5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(grades_20_21[ 'Total Homeworks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39153767-3e23-4c86-b453-011a36b23701",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[ 'Total Homeworks'].plot(kind='box'),grades_20_21[ 'Total Homeworks'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fadcc-4550-4a49-bd90-9f7e0f5a5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = \n",
    "X =  'Total Homeworks'\n",
    "# res = stats.linregress(sessions_attributes_fine_grained_multi[X], sessions_attributes_fine_grained_multi[Y])\n",
    "# rvalue, pvalue = stats.pearsonr(x=sessions_attributes_fine_grained_multi[X], y=sessions_attributes_fine_grained_multi[Y])\n",
    "# print(f\"R: {res.rvalue}\")\n",
    "# print(\"P-value\", pvalue)\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "gfg = sns.ecdfplot(data=grades_20_21, x=X)\n",
    " \n",
    "axs.set_xlabel( xlabel='Final Exam score', fontsize = 12 ) \n",
    "axs.set_ylabel( ylabel='Proportion', fontsize = 12) \n",
    "# plt.legend(loc='upper right',  frameon=True,  shadow=True, title='r = -0.269\\np-value = 0.002')\n",
    "plt.show()\n",
    "# fig.savefig(\"Final-Exam-Score-CDF.pdf\", facecolor=\"white\",dpi=500)\n",
    "\n",
    "# It means whether there are multiple number of choices or not, we may classifiy it as credit seeking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea9779-48a4-46ab-aa1a-a9c645102316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee46561-17b6-4b73-b0d0-aecdb675a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "73.000000-1.5*(93.000000-73.000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3632aa-4646-4eba-b0cd-70b81f65af99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(grades_20_21, agg_count_mid, how='inner',  left_index=True, right_index=True)\n",
    "# merged_df.set_index( 'odsa_ID', inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec0c13-d67a-4f82-a97f-53a99773ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df[\"result\"].to_numpy()\n",
    "all_y_numerical = merged_df[ 'Total Homeworks'].to_numpy()\n",
    "all_X = merged_df.iloc[:,2:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415a0ee-0a93-4527-a4a1-8ec39c4f61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = merged_df.iloc[:,2:]\n",
    "all_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9c00a-5c69-4fbd-8432-f5af0041801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[ 'Total Homeworks'].min(), merged_df[ 'Total Homeworks'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038585f-5005-4be8-997e-08516f8bf701",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5fbe8-fbaf-41af-a93c-437a89211514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e14c2f-0f55-4c50-8fe9-5958c6f6f847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sm = RandomOverSampler('minority')#\n",
    "all_X, all_y, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "all_X =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# sm = SMOTE('all')#\n",
    "# X_train, y_train, = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "clf = svm.SVC(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pickle.dump(clf, open( \"SVC-Midterm2\", \"wb\" ))\n",
    "\n",
    "# We were able to get Cross-validation score: 0.6152046783625732\n",
    "# Test score: 0.7446808510638298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c96aa-f2f9-4f24-be1d-b81a5915e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sm = RandomOverSampler('minority')#\n",
    "all_X, all_y, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "all_X =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# sm = SMOTE('all')#\n",
    "# X_train, y_train, = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# pickle.dump(clf, open( \"SVC-Midterm2\", \"wb\" ))\n",
    "\n",
    "# We were able to get Cross-validation score: 0.6152046783625732\n",
    "# Test score: 0.7446808510638298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aeb06e-3014-4733-99b3-5115822709c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[:,3:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fd9de-28b3-47f4-b6c6-4c53526dd9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea50531-b16c-4162-892b-bcc1ecb07059",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3df55b-907e-4953-a448-3ea5faafe0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- Random Classifier ----------------------------------------------------------------------------\n",
    "import random\n",
    "random_guessing = ['0.0', '1.0','2.0','3.0']\n",
    "\n",
    "sm = RandomOverSampler(sampling_strategy='all')#\n",
    "all_X = merged_df.iloc[:,2:]\n",
    "\n",
    "all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "\n",
    "\n",
    "all_y_predicted = []\n",
    "for i in range(len(all_y)):\n",
    "    all_y_predicted.append(random.choice(random_guessing))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy_score(all_y,all_y_predicted) ,2))\n",
    "print(\"F1-Score:\", round(f1_score(all_y,all_y_predicted, average= 'micro'),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba9570-df4f-42f3-adcf-0450398b8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- Constant Classifier ----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "all_ones = np.ones((123,50))\n",
    "all_ones.shape\n",
    "sm = RandomOverSampler(sampling_strategy='all')#\n",
    "all_y = merged_df[\"result\"].to_numpy()\n",
    "all_X = all_ones\n",
    "all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "       'prec_macro': 'precision_macro',\n",
    "       'rec_micro': 'recall_macro',\n",
    "          'f1_micro': 'f1_macro'}\n",
    "\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10,\n",
    "                                       shuffle=True,)\n",
    "\n",
    "scores = cross_validate(clf, all_X_normalized, all_y_oversampled, cv=10,scoring=scoring)\n",
    "print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442380c-3278-496d-a29e-ff4a0b4c647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "for i in range(20):\n",
    "    cv_scores = []\n",
    "    sm = RandomOverSampler(sampling_strategy='all')#\n",
    "    all_y = merged_df[\"result\"].to_numpy()\n",
    "    all_X = merged_df.iloc[:,3:] \n",
    "    \n",
    "    all_X_oversampled, all_y_oversampled, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "    all_X_normalized =  StandardScaler().fit_transform(all_X_oversampled) # StandardScaler, MinMaxScaler\n",
    "\n",
    "    clf = GradientBoostingClassifier()\n",
    "\n",
    "    scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_micro': 'recall_macro',\n",
    "              'f1_micro': 'f1_macro'}\n",
    "    \n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,\n",
    "                                           shuffle=True,)\n",
    "\n",
    "    scores = cross_validate(clf, all_X_normalized, all_y_oversampled, cv=10,scoring=scoring)\n",
    "    print(\"Accuracy:\", round(np.mean(scores['test_acc']),2))\n",
    "    print(\"F1-Score:\", round(np.mean(scores['test_f1_micro']),2))\n",
    "    print()\n",
    "    cv_scores.append( np.mean(scores['test_acc']))\n",
    "\n",
    "# Accuracy: 0.72 (Using all the data)\n",
    "# F1-Score: 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12560082-94ff-46a7-a54f-1559e052b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c21a8-4ae5-4b18-b449-63e608120dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sm = RandomOverSampler()#\n",
    "all_X, all_y, = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "\n",
    "all_X =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "cv_score = np.mean(cross_val_score(clf, X_train, y_train, cv=10))\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b196e-457a-48cf-9af6-303242618e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f92c-e6dc-4384-9d1f-6922c490a1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "\n",
    "all_X_normalized =  StandardScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X_normalized,\n",
    "                                                    all_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=all_y,\n",
    "                                                    random_state=11)\n",
    "\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(sampling_strategy='all', random_state=11)],\n",
    "                                ['classifier', LogisticRegression()]])\n",
    "\n",
    "# stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "#                                        shuffle=True,\n",
    "#                                        random_state=11)\n",
    "    \n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],       'classifier__penalty' : ['l1', 'l2'],      'classifier__C' : np.logspace(-4, 4, 20),    'classifier__solver' : ['liblinear'],\n",
    "       # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', ]\n",
    "    },\n",
    "       { \n",
    "     'classifier' : [ LinearSVC(max_iter=3000)],     \n",
    "       },\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],     'classifier__n_estimators' : list(range(10,101,10)), 'classifier__bootstrap': [True],     'classifier__max_depth': [80, 90, 100, 110], \n",
    "    'classifier__min_samples_leaf': [3, 4, 5], 'classifier__min_samples_split': [8, 10, 12], # 'smote__sampling_strategy':['minority', 'not minority', 'not majority', 'all']\n",
    "   } ,]\n",
    "\n",
    " # 'classifier__max_features': [2, 3],\n",
    "        \n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           # scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf568b-c2ff-45ca-a1ca-5df8c876cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778020e3-a3a0-4aec-8a9f-c46aaf4ccdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import svm\n",
    "all_X_normalized =  MinMaxScaler().fit_transform(all_X) # StandardScaler, MinMaxScaler\n",
    "all_Y_normalized =  MinMaxScaler().fit_transform(all_y_numerical.reshape(-1, 1)) # StandardScaler, MinMaxScaler\n",
    "\n",
    "# pca_model = PCA(n_components=3).fit(all_X_normalized)\n",
    "# all_X_normalized = pca_model.transform(all_X_normalized)\n",
    "# print(pca_model.explained_variance_ratio_ , sum(pca_model.explained_variance_ratio_)) #69.6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y_numerical, test_size=0.2, shuffle=True,  )\n",
    "\n",
    "# sm = RandomOverSampler()#\n",
    "# X_train  = sm.fit_resample(X_train )\n",
    "\n",
    "\n",
    "krr = svm.SVR() \n",
    "krr.fit(X_train, y_train.ravel())\n",
    "print(krr.score(X_test, y_test.ravel()))\n",
    "y_pred = krr.predict(X_test)\n",
    "\n",
    "# A constant model that always predicts the expected value of y, disregarding the input features, would get a  score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a8e30-0c48-4a91-a1f0-6fc37c0c2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce626-df24-4777-8f58-a62ff8be9d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4bdbc-dd7d-44e8-8f63-f27d0c54afce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a feature attribute\n",
    "\n",
    "# new_df_crsk_count = pd.DataFrame( columns= ['UserID']+framset_names) \n",
    "# new_df_crsk_count['UserID'] = userIDs\n",
    "# new_df_crsk_count.set_index( 'UserID', inplace=True) \n",
    "# new_df_crsk_count = new_df_crsk_count.fillna(0)\n",
    "\n",
    "# new_df_normal_count = new_df_crsk_count.copy()\n",
    "\n",
    "# new_df_agg = new_df_crsk_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528db2a-7e7e-496f-b5a5-9c6ef6f4e431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Credit Seeking':\n",
    "#         new_df_crsk_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# for session in sessions_df.iterrows():\n",
    "#     if session[1].Cluster == 'Normal':\n",
    "#         new_df_normal_count.loc[session[1].UserID][session[1].FramesetName]+=1\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# for row_id in range(len(new_df_normal_count)):\n",
    "#     for col_id in range(len(new_df_normal_count.columns)):\n",
    "#         new_df_agg.iloc[row_id, col_id] = new_df_normal_count.iloc[row_id, col_id] / (new_df_crsk_count.iloc[row_id, col_id]+new_df_normal_count.iloc[row_id, col_id])\n",
    "        \n",
    "# new_df_agg = new_df_agg.fillna(0)\n",
    "        \n",
    "# # We want the values to be Percentage of credit seeking of each frameset, instead of just raw values of credit seeking\n",
    "\n",
    "# new_df_normal_count[\"CrSk Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "# new_df_normal_count[\"Normal Sum\"] =  new_df_normal_count.sum(axis=1)\n",
    "\n",
    "# new_df_crsk_count.to_csv(\"new_df_crsk_count.csv\")\n",
    "# new_df_normal_count.to_csv(\"new_df_normal_count.csv\")\n",
    "# new_df_agg.to_csv(\"new_df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce993c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://udc.vt.edu/irdata/data/courses/grades\n",
    "# In Fall 2020, we have 70 enrollments \n",
    "# In Spring 2021, we have 65 enrollments\n",
    "# In Spring 2022, we have 75 enrollments\n",
    "\n",
    "# So having a file \"Coarse-grained_Clustered_Sessions.csv\" means \n",
    "# there's something wrong and we must remove students/accounts to sum up to 70+65 = 135. in Fall'20 and Spring'21. \n",
    "# For example, 1270 is Mostafa Mohammed \n",
    "\n",
    "# Correctly in \"Grades_Users.csv\", we have 133 students, and maybe 2 has dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680348f",
   "metadata": {},
   "source": [
    "# Regressor or Classifier based on \"Count of Normal in each frameset separately\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511f92a-28e7-4210-8c70-31f9288bf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b6b96-c373-407f-840c-677637780969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I report the model I used, write clearly why exactly this model, not any other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad0fdf-78ab-42b9-b748-2244bd957310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df_agg  = pd.read_csv('new_df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddc817-9f72-4523-bacf-17a9b66fbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any student who has been registered in two semesters ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00e041-b4bd-48e4-8841-7f8750d4461a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grades_22 = pd.read_csv(\"../Spring_22/all_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21 = pd.read_excel(\"../Grades/Book1.xlsx\")\n",
    "grades_20_21.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b24941-b226-4b21-9c4c-5c0912240a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6a82-26ac-4e6a-9f62-657df072e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no duplicate users between any of the three semester الحمدلله\n",
    "\n",
    "userIDs_22= grades_22.odsa_ID.unique()\n",
    "userIDs_20_21 = grades_20_21['OpenDSA ID'].unique()\n",
    "\n",
    "for user in userIDs_22:\n",
    "    if user in userIDs_20_21:\n",
    "        print(user)\n",
    "print('-'*100)      \n",
    "for user in userIDs_20_21:\n",
    "    if user in userIDs_22:\n",
    "        print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e748fc9-d1cc-4e5e-9760-ff67018efec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://courses.cs.vt.edu/~cs1604/grading.html\n",
    "\n",
    "letter_grade = []\n",
    "for grade in grades_20_21[\"Final Score\"]:\n",
    "    if grade >= 90:\n",
    "        letter_grade.append(\"A\")\n",
    "    elif grade >= 80:\n",
    "        letter_grade.append(\"B\")\n",
    "    elif grade >= 70:\n",
    "        letter_grade.append(\"C\")\n",
    "    elif grade >= 60:\n",
    "        letter_grade.append(\"D\")\n",
    "    else:\n",
    "        letter_grade.append(\"F\")\n",
    "\n",
    "grades_20_21[\"Letter Grade\"] = letter_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20541564-cfbb-4ade-a425-ad8e24f581ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_20_21[\"Letter Grade\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93633e89-5648-41b0-a1cc-34f68bcde69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebb6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(grades_20_21[['OpenDSA ID',\"Letter Grade\"]], new_df_agg, how='inner', left_on='OpenDSA ID', right_on='UserID')\n",
    "merged_df.set_index( 'UserID', inplace=True) \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'D'] # Because unbalanced with D and F. So, I am dropping them. \n",
    "merged_df = merged_df[merged_df[\"Letter Grade\"] != 'F'] # Because unbalanced with D and F. So, I am dropping them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = merged_df[\"Letter Grade\"].to_numpy()\n",
    "all_X = merged_df.iloc[:,2:] # Skips the other columns that come from the merge with Grades csv, -1 to skip the sum col. originally use [:,8:] for new_df_crsk_count, new_df_normal_count but not new_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36b3ae-eff5-4a7d-833f-4658f093b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8e79-584c-44e0-af87-3dc7ced6cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df[\"Letter Grade\"].value_counts())\n",
    "merged_df[\"Letter Grade\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1972b8-074f-4a3b-a02d-f6defdaa8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "58+41+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "all_X_normalized = scaler_X.fit_transform(all_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    all_X, all_y, test_size=0.3, shuffle=True)  # , random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99333-a134-4c7e-8437-7579d8cbc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverSampling\n",
    "\n",
    "sm = RandomOverSampler(sampling_strategy='minority')\n",
    "X_oversampled, y_oversampled = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversampled, y_oversampled, test_size=0.3, shuffle=True)  # \n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9b37-f04a-476e-a0a8-9c6abf795520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OverSampling\n",
    "\n",
    "sm = RandomOverSampler(sampling_strategy='minority')\n",
    "X_oversampled, y_oversampled = sm.fit_resample(all_X, all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversampled, y_oversampled, test_size=0.3, shuffle=True)  # \n",
    "\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a98e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))\n",
    "\n",
    "# 0.6875 --> The best I got earlier 3 months ago\n",
    "# ['A' 'A' 'B' 'A' 'C' 'C' 'B' 'B' 'C' 'B' 'B' 'C' 'A' 'C' 'C' 'A' 'B' 'B'\n",
    "#  'C' 'C' 'B' 'C' 'A' 'B' 'A' 'C' 'B' 'B' 'C' 'A' 'A' 'C']\n",
    "# [0.47058824 0.60869565 0.91666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d1acd-c7e6-486e-a810-2c4dc73f93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    { \n",
    "     'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    { \n",
    "     'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "    ,\n",
    "   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(best_clf.score(X_test, y_test))\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56555315-b347-45aa-97df-ee8237324d24",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print(\"Predicted:\", y_pred[i], \" -- Reality\",y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + GridSearchCV: we got accuracy of 66.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression + SMOTE: we got accuracy of 58.3% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + LogisticRegression: we got accuracy of 41.6% \n",
    "# Using 'Credit Seeking' and removing 'D' and 'F' + MinMax + DL (111,50,25,3): we got accuracy of 41.6% \n",
    "\n",
    "# Using \n",
    "# I have tried reducing the dimensions using PCA, and it turns out we can reduce to 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335320cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=111, n_hidden=45, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.ReLU(),\n",
    "             nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X_normalized, all_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "\n",
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeafcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af175f86-22bb-42d4-be8b-9da547eb0ccd",
   "metadata": {},
   "source": [
    "# Regressor or Classifier based on \"Student % of CrSk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14a8a0-7663-4411-913e-0324e7f6241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as FM\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "import gc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "# pl.utilities.seed.seed_everything(seed=2) # sets seed for pseudo-random number generators in: pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9c32a-454b-4311-ad2a-63d74f6c8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustered_Users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03eac2-be08-4dba-8017-1cfca84f705c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_X =  Clustered_Users[['# CrSk Attempts','# Nrml Attempts','% of CrSk',\n",
    "#                     'Is CrSk','CrSk Time','Nrml Time','# CrSk Framesets','# Nrml Framesets']].to_numpy()\n",
    "\n",
    "all_X = Clustered_Users[\n",
    "    [\n",
    "        \"# CrSk Attempts\",\n",
    "        \"% of CrSk\",\n",
    "        \"Is CrSk\",\n",
    "        \"CrSk Time\",\n",
    "        \"# CrSk Framesets\",\n",
    "    ]\n",
    "].to_numpy()\n",
    "all_y = Clustered_Users[\"Letter Grade\"].to_numpy()\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "all_X = scaler_X.fit_transform(all_X)\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "all_y = le_y.fit_transform(all_y)\n",
    "# scaler_y = StandardScaler()\n",
    "# all_y = scaler_y.fit_transform(all_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_X, all_y, test_size=0.2, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33542ff-e5a0-4e54-a146-309404cd9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876a42b-cbd0-44b5-ba94-0fa917851620",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bc48c-dcdf-48f1-b39e-4e4757d1d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b58d8-ca59-447b-a73c-aa210a943054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fada2b-aeba-4e83-80d6-d4cd733138f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# 1- Normalized Version of Credit Seeking\n",
    "# 2- Normalized Version of Normal\n",
    "# 3- Normalized Version of # of framesets in Credit Seeking\n",
    "# 4- Normalized Version of # of framesets in Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00aa373-92c3-4e91-b2b3-0931290a7997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModelRegressor(pl.LightningModule):\n",
    "    def __init__(self, n_features=2, n_hidden=128, n_output=3):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = FM.mean_squared_error(y_hat, y)\n",
    "        self.log(\"MSE\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b242fa4-16a2-4464-b00e-df29f741cab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(pl.LightningModule):\n",
    "    def __init__(self, n_features=5, n_hidden=50, n_output=5):\n",
    "        super().__init__()\n",
    "        # need to be (self) in order to be optimized and part of model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # y_hat is (N, C) and y is (N)\n",
    "        acc = FM.accuracy(F.softmax(y_hat, 1), y)\n",
    "        self.log(\n",
    "            \"accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbfa08-7803-4a94-9901-e34330be6789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params = {'shuffle': True,'num_workers': 0,'batch_size':256}\n",
    "params = {\"shuffle\": True}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train.to(device), y_train.to(device))\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_test.to(device), y_test.to(device))\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "    model = MLPModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, progress_bar_refresh_rate=1)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c48364-6e33-4ba1-8a5d-9fb60715fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Feature: % of Cr Seeking (Standridzed) with many hyperparameters, and the best MSE is 1.1431, Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized),                 and the best MSE is 1.220 , Y = Final Score\n",
    "# Two Feature: (Credit Seeking, Normal) (Standardized), and the best MSE is 1.00264 , Y = (Midterm 1, Midterm 2, Final Exam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
